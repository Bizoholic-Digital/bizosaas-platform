#!/usr/bin/env python3
"""
Demo script for Amazon Data Scraper
Showcases real vs placeholder data comparison
"""

import asyncio
import sys
sys.path.append('.')

from amazon_sourcing_service import AmazonDataScraper, logger

async def demo_real_vs_placeholder():
    """Demo showing real Amazon data vs placeholder data"""
    
    print("üöÄ Amazon Data Scraper Demo")
    print("=" * 50)
    
    scraper = AmazonDataScraper()
    
    # Test verified ASINs
    test_asins = [
        ("B0CR7G9V56", "Bodyband Abs Roller"),
        ("B0DX1QJFK4", "Boldfit Yoga Mat"),
        ("B0FGYDCPRR", "pTron Bassbuds Earbuds"),
    ]
    
    try:
        for asin, product_name in test_asins:
            print(f"\nüì¶ Testing: {product_name} ({asin})")
            print("-" * 40)
            
            # Scrape real data
            scraped_data = await scraper.scrape_product_data(asin)
            
            # Show comparison
            print("üîç REAL AMAZON DATA:")
            print(f"   Success: {'‚úÖ Yes' if scraped_data.get('success') else '‚ùå No'}")
            print(f"   Title: {scraped_data.get('title', 'N/A')}")
            print(f"   Price: ‚Çπ{scraped_data.get('price', 'N/A')}")
            print(f"   Rating: {scraped_data.get('rating', 'N/A')}/5")
            print(f"   Reviews: {scraped_data.get('review_count', 'N/A')}")
            print(f"   Availability: {scraped_data.get('availability', 'N/A')}")
            
            if scraped_data.get('image_url'):
                print(f"   Image URL: {scraped_data['image_url'][:60]}...")
                print("   üñºÔ∏è  Real Amazon Image Found!")
            else:
                print("   üì∑ No image found - would use placeholder")
            
            # Show fallback data for comparison
            if not scraped_data.get('success'):
                print("\nüîÑ FALLBACK DATA:")
                print("   Would use placeholder image: /images/product-placeholder-1.jpg")
                print("   Would use estimated price from product database")
            
            print(f"   üåê Product URL: https://www.amazon.in/dp/{asin}")
            
    except Exception as e:
        print(f"‚ùå Demo failed: {str(e)}")
    finally:
        await scraper.close()

async def demo_price_comparison():
    """Demo showing price accuracy"""
    
    print(f"\nüí∞ Price Accuracy Demo")
    print("=" * 30)
    
    scraper = AmazonDataScraper()
    
    expected_prices = {
        "B0CR7G9V56": (179, 199),  # Bodyband Abs Roller
        "B0DX1QJFK4": (379, 449),  # Boldfit Yoga Mat
        "B0FGYDCPRR": (999, 1199), # pTron Bassbuds
    }
    
    try:
        for asin, (min_price, max_price) in expected_prices.items():
            scraped_data = await scraper.scrape_product_data(asin)
            real_price = scraped_data.get('price')
            
            print(f"üìä ASIN {asin}:")
            print(f"   Expected Range: ‚Çπ{min_price} - ‚Çπ{max_price}")
            print(f"   Scraped Price: ‚Çπ{real_price}")
            
            if real_price:
                if min_price <= real_price <= max_price:
                    print(f"   ‚úÖ Price within expected range!")
                else:
                    print(f"   ‚ö†Ô∏è  Price outside expected range (market fluctuation)")
            else:
                print(f"   ‚ùå Could not extract price")
            
    except Exception as e:
        print(f"‚ùå Price demo failed: {str(e)}")
    finally:
        await scraper.close()

async def demo_caching():
    """Demo showing caching functionality"""
    
    print(f"\n‚ö° Caching Demo")
    print("=" * 20)
    
    scraper = AmazonDataScraper()
    test_asin = "B0CR7G9V56"
    
    try:
        # First request (should scrape)
        print("üåê First request (will scrape from Amazon)...")
        start_time = asyncio.get_event_loop().time()
        data1 = await scraper.scrape_product_data(test_asin)
        first_duration = asyncio.get_event_loop().time() - start_time
        print(f"   Duration: {first_duration:.2f} seconds")
        print(f"   Cached: {'No' if data1.get('success') else 'N/A'}")
        
        # Second request (should use cache)
        print("‚ö° Second request (should use cache)...")
        start_time = asyncio.get_event_loop().time()
        data2 = await scraper.scrape_product_data(test_asin)
        second_duration = asyncio.get_event_loop().time() - start_time
        print(f"   Duration: {second_duration:.2f} seconds")
        print(f"   Cached: Yes")
        
        print(f"üöÄ Speed improvement: {first_duration/second_duration:.1f}x faster!")
        print(f"üìä Cache size: {len(scraper.cache)} items")
        
    except Exception as e:
        print(f"‚ùå Caching demo failed: {str(e)}")
    finally:
        await scraper.close()

async def main():
    """Run all demos"""
    await demo_real_vs_placeholder()
    await demo_price_comparison()
    await demo_caching()
    
    print(f"\nüéØ Demo Complete!")
    print("üìö Next steps:")
    print("   1. Start the service: python amazon_sourcing_service.py")
    print("   2. Test the API: curl 'http://localhost:8080/scraper/test/B0CR7G9V56'")
    print("   3. Run comprehensive tests: python test_scraper.py")

if __name__ == "__main__":
    asyncio.run(main())