version: '3.8'

services:
  # Apache Superset Analytics Engine
  superset-db:
    image: postgres:15-alpine
    container_name: bizosaas-superset-db
    environment:
      POSTGRES_DB: superset
      POSTGRES_USER: superset
      POSTGRES_PASSWORD: ${SUPERSET_DB_PASSWORD:-superset_secure_password}
    volumes:
      - superset_db_data:/var/lib/postgresql/data
    networks:
      - analytics-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U superset"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for Superset caching
  superset-redis:
    image: redis:7-alpine
    container_name: bizosaas-superset-redis
    command: redis-server --requirepass ${SUPERSET_REDIS_PASSWORD:-redis_secure_password}
    volumes:
      - superset_redis_data:/data
    networks:
      - analytics-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5


  # Apache Superset
  superset:
    image: apache/superset:latest
    container_name: bizosaas-superset
    environment:
      # Database Configuration
      SUPERSET_CONFIG_PATH: /app/pythonpath/superset_config.py
      DATABASE_DIALECT: postgresql
      DATABASE_USER: superset
      DATABASE_PASSWORD: ${SUPERSET_DB_PASSWORD:-superset_secure_password}
      DATABASE_HOST: superset-db
      DATABASE_PORT: 5432
      DATABASE_DB: superset
      
      # Redis Configuration
      REDIS_HOST: superset-redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${SUPERSET_REDIS_PASSWORD:-redis_secure_password}
      
      # Security
      SECRET_KEY: ${SUPERSET_SECRET_KEY:-your-super-secret-key-change-in-production}
      SUPERSET_LOAD_EXAMPLES: "no"
      
      # Multi-tenant Configuration
      FEATURE_FLAGS: >
        {
          "ENABLE_TEMPLATE_PROCESSING": True,
          "ROW_LEVEL_SECURITY": True,
          "DASHBOARD_FILTERS_EXPERIMENTAL": True,
          "DASHBOARD_NATIVE_FILTERS": True,
          "GLOBAL_ASYNC_QUERIES": True,
          "VERSIONED_EXPORT": True
        }
      
      # Brain API Integration
      BRAIN_API_URL: ${BRAIN_API_URL:-http://brain-api:8001}
      BRAIN_API_TOKEN: ${BRAIN_API_TOKEN:-brain_api_secure_token}
      
      # Tenant Configuration
      DEFAULT_TENANT_ID: ${DEFAULT_TENANT_ID:-demo}
    
    volumes:
      - ./superset/config:/app/pythonpath
      - ./superset/dashboards:/app/superset_home/dashboards
      - superset_app_data:/app/superset_home
    
    ports:
      - "8088:8088"
    
    networks:
      - analytics-network
      - brain-network
    
    depends_on:
      superset-db:
        condition: service_healthy
      superset-redis:
        condition: service_healthy
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    command: >
      bash -c "
        superset fab create-admin --username admin --firstname Admin --lastname User --email admin@bizosaas.com --password ${SUPERSET_ADMIN_PASSWORD:-admin_secure_password} || true &&
        superset db upgrade &&
        superset init &&
        superset run -p 8088 -h 0.0.0.0 --with-threads --reload --debugger
      "

  # ClickHouse for high-performance analytics (optional)
  clickhouse:
    image: clickhouse/clickhouse-server:23.8-alpine
    container_name: bizosaas-clickhouse
    environment:
      CLICKHOUSE_DB: analytics
      CLICKHOUSE_USER: analytics
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-clickhouse_secure_password}
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./clickhouse/config.xml:/etc/clickhouse-server/config.xml:ro
      - ./clickhouse/users.xml:/etc/clickhouse-server/users.xml:ro
    ports:
      - "8123:8123"  # HTTP interface
      - "9000:9000"  # Native client
    networks:
      - analytics-network
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Analytics Data Pipeline (optional - for ETL)
  analytics-etl:
    build:
      context: ./services/analytics-etl
      dockerfile: Dockerfile
    container_name: bizosaas-analytics-etl
    environment:
      BRAIN_API_URL: http://brain-api:8001
      SUPERSET_URL: http://superset:8088
      CLICKHOUSE_URL: http://clickhouse:8123
      POSTGRES_URL: postgresql://superset:${SUPERSET_DB_PASSWORD:-superset_secure_password}@superset-db:5432/superset
      
      # External API Credentials (encrypted in Vault)
      GOOGLE_ANALYTICS_CREDENTIALS: ${GOOGLE_ANALYTICS_CREDENTIALS}
      FACEBOOK_API_TOKEN: ${FACEBOOK_API_TOKEN}
      BING_ADS_CREDENTIALS: ${BING_ADS_CREDENTIALS}
      
      # Scheduling
      ETL_SCHEDULE: "0 */4 * * *"  # Every 4 hours
    
    volumes:
      - analytics_etl_logs:/app/logs
    
    networks:
      - analytics-network
      - brain-network
    
    depends_on:
      - superset
      - clickhouse
    
    restart: unless-stopped

volumes:
  superset_db_data:
    driver: local
  superset_redis_data:
    driver: local
  superset_app_data:
    driver: local
  clickhouse_data:
    driver: local
  analytics_etl_logs:
    driver: local

networks:
  analytics-network:
    driver: bridge
    name: bizosaas-analytics
  brain-network:
    driver: bridge
    name: bizosaas-brain