#!/usr/bin/env python3
"""
Comprehensive Test Suite for Amazon Vendor Central APIs Integration
Tests all 4 AI agents and their coordination through the Brain API Gateway

This test suite validates:
- Vendor Operations Management Agent functionality
- Vendor Performance Analytics Agent functionality  
- Vendor Content Optimization Agent functionality
- Vendor Financial Management Agent functionality
- Integration with Brain API Gateway
- Multi-agent coordination and data flow

Author: AI Assistant
Created: 2025-01-14
Version: 1.0.0
"""

import asyncio
import json
import httpx
from datetime import datetime, timedelta
from typing import Dict, List, Any

# Test configuration
BASE_URL = "http://localhost:8001"
BRAIN_API_BASE = "/api/brain/integrations/amazon-vendor-central"

# Test data for realistic vendor scenarios
TEST_VENDOR_DATA = {
    "vendor_id": "VND-TEST-12345",
    "vendor_name": "Premium Electronics Vendor",
    "category": "electronics",
    "marketplace": "US"
}

TEST_OPERATIONS_DATA = {
    "vendor_id": TEST_VENDOR_DATA["vendor_id"],
    "operation_type": "purchase_order",
    "operation_details": {
        "po_number": "PO-2025-001234",
        "product_lines": 15,
        "total_units": 5000,
        "delivery_date": "2025-02-15",
        "priority": "high"
    },
    "priority": "high",
    "expected_completion": "2025-01-20",
    "metadata": {
        "automated": True,
        "notification_enabled": True
    }
}

TEST_PERFORMANCE_DATA = {
    "vendor_id": TEST_VENDOR_DATA["vendor_id"],
    "metrics_scope": ["sales", "inventory", "operational", "financial"],
    "date_range": {
        "start_date": "2024-12-01",
        "end_date": "2024-12-31"
    },
    "comparison_period": {
        "start_date": "2024-11-01",
        "end_date": "2024-11-30"
    },
    "granularity": "daily",
    "metadata": {
        "include_forecasting": True,
        "benchmark_comparison": True
    }
}

TEST_CONTENT_DATA = {
    "vendor_id": TEST_VENDOR_DATA["vendor_id"],
    "content_type": "product_listing",
    "products": [
        {
            "asin": "B08X6QY789",
            "title": "Premium Wireless Bluetooth Headphones",
            "category": "Electronics",
            "current_performance": "moderate"
        },
        {
            "asin": "B09Y8ZT123",
            "title": "Smart Home Security Camera System",
            "category": "Security",
            "current_performance": "low"
        }
    ],
    "optimization_goals": ["conversion_rate", "seo_ranking", "customer_engagement"],
    "brand_guidelines": {
        "tone": "professional",
        "style": "modern",
        "target_audience": "tech_enthusiasts"
    },
    "metadata": {
        "urgency": "medium",
        "budget_allocation": 15000
    }
}

TEST_FINANCIAL_DATA = {
    "vendor_id": TEST_VENDOR_DATA["vendor_id"],
    "financial_type": "invoice_management",
    "transaction_details": {
        "invoice_number": "INV-2025-007834",
        "amount": 125000.00,
        "currency": "USD",
        "due_date": "2025-02-10",
        "po_reference": "PO-2025-001234"
    },
    "reconciliation_period": {
        "start_date": "2024-12-01", 
        "end_date": "2024-12-31"
    },
    "dispute_handling": {
        "auto_resolve": True,
        "escalation_threshold": 5000
    },
    "metadata": {
        "payment_terms": "NET30",
        "early_payment_discount": 2.0
    }
}

class AmazonVendorCentralAPITester:
    """Comprehensive tester for Amazon Vendor Central API integration"""
    
    def __init__(self):
        self.client = httpx.AsyncClient(timeout=30.0)
        self.test_results = []
        
    async def test_vendor_operations_management(self) -> Dict[str, Any]:
        """Test Vendor Operations Management Agent functionality"""
        print("ğŸ­ Testing Vendor Operations Management Agent...")
        
        endpoint = f"{BRAIN_API_BASE}/ai-vendor-operations-management"
        
        try:
            response = await self.client.post(
                f"{BASE_URL}{endpoint}",
                json=TEST_OPERATIONS_DATA
            )
            
            assert response.status_code == 200, f"Expected 200, got {response.status_code}"
            result = response.json()
            
            # Validate response structure
            assert "status" in result, "Response missing status field"
            assert "agent_id" in result, "Response missing agent_id"
            assert "vendor_id" in result, "Response missing vendor_id"
            assert "operations_analysis" in result, "Response missing operations_analysis"
            assert "optimization_plan" in result, "Response missing optimization_plan"
            assert "insights" in result, "Response missing insights"
            assert "recommendations" in result, "Response missing recommendations"
            assert "performance_metrics" in result, "Response missing performance_metrics"
            
            # Validate vendor operations specific fields
            assert result["vendor_id"] == TEST_VENDOR_DATA["vendor_id"]
            assert result["operation_type"] == "purchase_order"
            assert result["status"] == "success"
            assert len(result["insights"]) > 0
            assert len(result["recommendations"]) > 0
            
            # Validate operations analysis structure
            ops_analysis = result["operations_analysis"]
            assert "po_volume" in ops_analysis or "fulfillment_rate" in ops_analysis
            
            # Validate optimization plan
            opt_plan = result["optimization_plan"]
            assert "optimization_strategy" in opt_plan
            assert "expected_improvement" in opt_plan
            
            print("âœ… Vendor Operations Management Agent test passed")
            return {
                "test": "vendor_operations_management",
                "status": "passed",
                "agent_id": result["agent_id"],
                "operations_optimized": True,
                "recommendations_count": len(result["recommendations"]),
                "insights_generated": len(result["insights"])
            }
            
        except Exception as e:
            print(f"âŒ Vendor Operations Management Agent test failed: {str(e)}")
            return {
                "test": "vendor_operations_management", 
                "status": "failed",
                "error": str(e)
            }
    
    async def test_vendor_performance_analytics(self) -> Dict[str, Any]:
        """Test Vendor Performance Analytics Agent functionality"""
        print("ğŸ“Š Testing Vendor Performance Analytics Agent...")
        
        endpoint = f"{BRAIN_API_BASE}/ai-vendor-performance-analytics"
        
        try:
            response = await self.client.post(
                f"{BASE_URL}{endpoint}",
                json=TEST_PERFORMANCE_DATA
            )
            
            assert response.status_code == 200, f"Expected 200, got {response.status_code}"
            result = response.json()
            
            # Validate response structure
            assert "status" in result, "Response missing status field"
            assert "agent_id" in result, "Response missing agent_id"
            assert "vendor_id" in result, "Response missing vendor_id"
            assert "performance_data" in result, "Response missing performance_data"
            assert "insights" in result, "Response missing insights"
            assert "benchmarks" in result, "Response missing benchmarks"
            assert "trends" in result, "Response missing trends"
            assert "recommendations" in result, "Response missing recommendations"
            assert "forecast" in result, "Response missing forecast"
            
            # Validate vendor performance specific fields
            assert result["vendor_id"] == TEST_VENDOR_DATA["vendor_id"]
            assert result["status"] == "success"
            assert result["metrics_scope"] == TEST_PERFORMANCE_DATA["metrics_scope"]
            
            # Validate performance data structure for each scope
            perf_data = result["performance_data"]
            for scope in TEST_PERFORMANCE_DATA["metrics_scope"]:
                if scope in perf_data:
                    scope_data = perf_data[scope]
                    assert isinstance(scope_data, dict), f"Scope {scope} data should be dict"
                    assert len(scope_data) > 0, f"Scope {scope} should have metrics"
            
            # Validate benchmarks
            benchmarks = result["benchmarks"]
            assert "industry_percentile" in benchmarks
            assert "performance_ranking" in benchmarks
            assert "competitive_position" in benchmarks
            
            # Validate forecast
            forecast = result["forecast"]
            assert "forecast_horizon" in forecast
            assert "revenue_projection" in forecast
            
            print("âœ… Vendor Performance Analytics Agent test passed")
            return {
                "test": "vendor_performance_analytics",
                "status": "passed",
                "agent_id": result["agent_id"],
                "metrics_analyzed": len(perf_data.keys()),
                "insights_generated": len(result["insights"]),
                "benchmarks_provided": True,
                "forecast_available": True
            }
            
        except Exception as e:
            print(f"âŒ Vendor Performance Analytics Agent test failed: {str(e)}")
            return {
                "test": "vendor_performance_analytics",
                "status": "failed", 
                "error": str(e)
            }
    
    async def test_vendor_content_optimization(self) -> Dict[str, Any]:
        """Test Vendor Content Optimization Agent functionality"""
        print("ğŸ“ Testing Vendor Content Optimization Agent...")
        
        endpoint = f"{BRAIN_API_BASE}/ai-vendor-content-optimization"
        
        try:
            response = await self.client.post(
                f"{BASE_URL}{endpoint}",
                json=TEST_CONTENT_DATA
            )
            
            assert response.status_code == 200, f"Expected 200, got {response.status_code}"
            result = response.json()
            
            # Validate response structure
            assert "status" in result, "Response missing status field"
            assert "agent_id" in result, "Response missing agent_id"
            assert "vendor_id" in result, "Response missing vendor_id"
            assert "content_analysis" in result, "Response missing content_analysis"
            assert "optimization_plan" in result, "Response missing optimization_plan"
            assert "generated_content" in result, "Response missing generated_content"
            assert "seo_recommendations" in result, "Response missing seo_recommendations"
            assert "performance_predictions" in result, "Response missing performance_predictions"
            
            # Validate vendor content specific fields
            assert result["vendor_id"] == TEST_VENDOR_DATA["vendor_id"]
            assert result["content_type"] == "product_listing"
            assert result["status"] == "success"
            assert result["products_optimized"] == len(TEST_CONTENT_DATA["products"])
            
            # Validate content analysis
            content_analysis = result["content_analysis"]
            assert "current_conversion_rate" in content_analysis or "seo_score" in content_analysis
            
            # Validate optimization plan
            opt_plan = result["optimization_plan"]
            assert "title_optimization" in opt_plan or "expected_improvement" in opt_plan
            
            # Validate generated content
            gen_content = result["generated_content"]
            assert "content_samples" in gen_content
            assert "optimization_score" in gen_content
            
            # Validate SEO recommendations
            seo_recs = result["seo_recommendations"]
            assert len(seo_recs) > 0
            for rec in seo_recs:
                assert "category" in rec
                assert "recommendation" in rec
                assert "priority" in rec
            
            # Validate performance predictions
            predictions = result["performance_predictions"]
            assert "conversion_rate_lift" in predictions
            assert "content_quality_score" in predictions
            
            print("âœ… Vendor Content Optimization Agent test passed")
            return {
                "test": "vendor_content_optimization",
                "status": "passed",
                "agent_id": result["agent_id"],
                "products_optimized": result["products_optimized"],
                "seo_recommendations": len(seo_recs),
                "content_quality_score": predictions.get("content_quality_score", 0)
            }
            
        except Exception as e:
            print(f"âŒ Vendor Content Optimization Agent test failed: {str(e)}")
            return {
                "test": "vendor_content_optimization",
                "status": "failed",
                "error": str(e)
            }
    
    async def test_vendor_financial_management(self) -> Dict[str, Any]:
        """Test Vendor Financial Management Agent functionality"""
        print("ğŸ’° Testing Vendor Financial Management Agent...")
        
        endpoint = f"{BRAIN_API_BASE}/ai-vendor-financial-management"
        
        try:
            response = await self.client.post(
                f"{BASE_URL}{endpoint}",
                json=TEST_FINANCIAL_DATA
            )
            
            assert response.status_code == 200, f"Expected 200, got {response.status_code}"
            result = response.json()
            
            # Validate response structure
            assert "status" in result, "Response missing status field"
            assert "agent_id" in result, "Response missing agent_id"
            assert "vendor_id" in result, "Response missing vendor_id"
            assert "financial_analysis" in result, "Response missing financial_analysis"
            assert "optimization_opportunities" in result, "Response missing optimization_opportunities"
            assert "reconciliation_results" in result, "Response missing reconciliation_results"
            assert "cost_savings_identified" in result, "Response missing cost_savings_identified"
            assert "recommendations" in result, "Response missing recommendations"
            assert "risk_assessment" in result, "Response missing risk_assessment"
            
            # Validate vendor financial specific fields
            assert result["vendor_id"] == TEST_VENDOR_DATA["vendor_id"]
            assert result["financial_type"] == "invoice_management"
            assert result["status"] == "success"
            
            # Validate financial analysis
            fin_analysis = result["financial_analysis"]
            assert "invoice_volume" in fin_analysis or "processing_accuracy" in fin_analysis
            
            # Validate optimization opportunities
            opt_opps = result["optimization_opportunities"]
            assert len(opt_opps) > 0
            for opp in opt_opps:
                assert "category" in opp
                assert "opportunity" in opp
                assert "potential_savings" in opp
            
            # Validate reconciliation results
            recon_results = result["reconciliation_results"]
            assert "reconciled_amount" in recon_results
            assert "accuracy_rate" in recon_results
            
            # Validate cost savings
            cost_savings = result["cost_savings_identified"]
            assert "immediate_savings" in cost_savings
            assert "annual_savings_potential" in cost_savings
            assert "roi_projection" in cost_savings
            
            # Validate risk assessment
            risk_assess = result["risk_assessment"]
            assert "risk_level" in risk_assess
            assert "financial_health_score" in risk_assess
            
            print("âœ… Vendor Financial Management Agent test passed")
            return {
                "test": "vendor_financial_management",
                "status": "passed",
                "agent_id": result["agent_id"],
                "optimization_opportunities": len(opt_opps),
                "financial_health_score": risk_assess.get("financial_health_score", 0),
                "annual_savings_potential": cost_savings.get("annual_savings_potential", 0)
            }
            
        except Exception as e:
            print(f"âŒ Vendor Financial Management Agent test failed: {str(e)}")
            return {
                "test": "vendor_financial_management",
                "status": "failed",
                "error": str(e)
            }
    
    async def test_agents_status(self) -> Dict[str, Any]:
        """Test Vendor Central AI agents status endpoint"""
        print("ğŸ” Testing Vendor Central AI Agents Status...")
        
        endpoint = f"{BRAIN_API_BASE}/ai-agents-status"
        
        try:
            response = await self.client.get(f"{BASE_URL}{endpoint}")
            
            assert response.status_code == 200, f"Expected 200, got {response.status_code}"
            result = response.json()
            
            # Validate response structure
            assert "system_status" in result, "Response missing system_status field"
            assert "total_agents" in result, "Response missing total_agents field"
            assert "active_agents" in result, "Response missing active_agents field"
            assert "system_health" in result, "Response missing system_health field"
            assert "agents" in result, "Response missing agents field"
            
            # Validate agents information
            agents = result["agents"]
            expected_agents = [
                "vendor_operations_agent",
                "vendor_performance_agent", 
                "vendor_content_agent",
                "vendor_financial_agent"
            ]
            
            for agent_name in expected_agents:
                assert agent_name in agents, f"Missing agent: {agent_name}"
                agent_info = agents[agent_name]
                assert "status" in agent_info, f"Agent {agent_name} missing status"
                assert "capabilities" in agent_info, f"Agent {agent_name} missing capabilities"
                assert "performance_metrics" in agent_info, f"Agent {agent_name} missing performance_metrics"
                assert agent_info["status"] == "active", f"Agent {agent_name} not active"
            
            # Validate system health
            assert result["system_status"] == "operational"
            assert result["total_agents"] == 4
            assert result["active_agents"] == 4
            assert result["system_health"] > 90.0
            
            print("âœ… Vendor Central AI Agents Status test passed")
            return {
                "test": "agents_status",
                "status": "passed",
                "total_agents": result["total_agents"],
                "active_agents": result["active_agents"],
                "system_health": result["system_health"],
                "all_agents_active": all(agent["status"] == "active" for agent in agents.values())
            }
            
        except Exception as e:
            print(f"âŒ Vendor Central AI Agents Status test failed: {str(e)}")
            return {
                "test": "agents_status",
                "status": "failed",
                "error": str(e)
            }
    
    async def run_comprehensive_test_suite(self) -> Dict[str, Any]:
        """Run comprehensive test suite for all Amazon Vendor Central AI agents"""
        print("ğŸš€ Starting Amazon Vendor Central APIs Integration Test Suite")
        print("=" * 80)
        
        # Run all individual tests
        test_methods = [
            self.test_vendor_operations_management,
            self.test_vendor_performance_analytics, 
            self.test_vendor_content_optimization,
            self.test_vendor_financial_management,
            self.test_agents_status
        ]
        
        results = []
        for test_method in test_methods:
            try:
                result = await test_method()
                results.append(result)
                await asyncio.sleep(0.5)  # Brief pause between tests
            except Exception as e:
                results.append({
                    "test": test_method.__name__,
                    "status": "failed",
                    "error": str(e)
                })
        
        # Calculate summary statistics
        passed_tests = [r for r in results if r.get("status") == "passed"]
        failed_tests = [r for r in results if r.get("status") == "failed"]
        
        success_rate = len(passed_tests) / len(results) * 100
        
        # Generate comprehensive report
        summary = {
            "test_suite": "Amazon Vendor Central APIs Integration",
            "timestamp": datetime.now().isoformat(),
            "total_tests": len(results),
            "passed_tests": len(passed_tests),
            "failed_tests": len(failed_tests),
            "success_rate": round(success_rate, 1),
            "overall_status": "SUCCESS" if success_rate == 100 else "PARTIAL_SUCCESS" if success_rate >= 80 else "FAILURE",
            "test_results": results,
            "vendor_data": TEST_VENDOR_DATA
        }
        
        print("=" * 80)
        print("ğŸ“Š AMAZON VENDOR CENTRAL API INTEGRATION TEST RESULTS")
        print("=" * 80)
        print(f"ğŸ­ Total Tests: {len(results)}")
        print(f"âœ… Passed Tests: {len(passed_tests)}")
        print(f"âŒ Failed Tests: {len(failed_tests)}")
        print(f"ğŸ“ˆ Success Rate: {success_rate}%")
        print(f"ğŸ¯ Overall Status: {summary['overall_status']}")
        
        if success_rate == 100:
            print("\nğŸ‰ ALL TESTS PASSED! Amazon Vendor Central API integration is fully operational")
            print("ğŸ­ 4 AI Agents successfully coordinating vendor operations management")
            
            # Print agent-specific success metrics
            for result in passed_tests:
                if result["test"] == "vendor_operations_management":
                    print(f"   ğŸ”§ Vendor Operations: {result['recommendations_count']} recommendations generated")
                elif result["test"] == "vendor_performance_analytics":
                    print(f"   ğŸ“Š Performance Analytics: {result['metrics_analyzed']} metrics analyzed")
                elif result["test"] == "vendor_content_optimization":
                    print(f"   ğŸ“ Content Optimization: {result['products_optimized']} products optimized")
                elif result["test"] == "vendor_financial_management":
                    print(f"   ğŸ’° Financial Management: ${result['annual_savings_potential']:,} savings identified")
        else:
            print("\nâš ï¸  SOME TESTS FAILED - Please check individual test results")
            for failed_test in failed_tests:
                print(f"   âŒ {failed_test['test']}: {failed_test.get('error', 'Unknown error')}")
        
        await self.client.aclose()
        return summary

async def main():
    """Main function to run the test suite"""
    tester = AmazonVendorCentralAPITester()
    results = await tester.run_comprehensive_test_suite()
    
    # Save results to file for further analysis
    with open("vendor_central_api_test_results.json", "w") as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ“„ Detailed test results saved to: vendor_central_api_test_results.json")
    return results

if __name__ == "__main__":
    asyncio.run(main())