"""
Quality Assurance Agent
-----------------------
This agent acts as a critic and auditor for other AI agents. 
It analyzes the outputs of workflows and tasks to ensure they meet 
quality standards before they are presented to the user.
"""

import json
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional
from crewai import Agent, Task, Crew, Process
from pydantic import BaseModel, Field

from .base_agent import BaseAgent, AgentRole, AgentTaskRequest

class QualityMetric(BaseModel):
    criteria: str
    score: int = Field(description="Score from 1-10")
    feedback: str
    pass_threshold: int = 7

class QualityReport(BaseModel):
    overall_score: float
    metrics: List[QualityMetric]
    is_approved: bool
    improvement_suggestions: List[str]
    audited_at: datetime

class RefinedQualityAssuranceAgent(BaseAgent):
    """
    AI Agent responsible for auditing and validating the output of other agents.
    """
    
    def __init__(self):
        super().__init__(
            agent_name="quality_assurance_auditor",
            agent_role=AgentRole.OPERATIONS,
            description="AI Quality Assurance Auditor ensuring high standards of output",
            version="1.0.0"
        )
        
        self.crewai_agent = Agent(
            role='Quality Assurance Auditor',
            goal='Rigorously evaluate AI-generated content for accuracy, completeness, and actionable value.',
            backstory="""You are a senior Quality Assurance Director with a keen eye for detail. 
            Your job is to review reports, strategies, and code generated by other AI agents. 
            You are critical but constructive. You do not accept vague, generic, or incomplete answers. 
            If a response lacks data, specifics, or logical flow, you flag it immediately.""",
            verbose=True,
            allow_delegation=False,
            # LLM Configuration is handled by environment variables (OpenAI/OpenRouter)
        )

    async def _execute_agent_logic(self, task_request: AgentTaskRequest) -> Dict[str, Any]:
        """
        Execute QA audit on provided content.
        Input data should include:
        - content_to_review: (str/dict) The output from another agent
        - context: (str) What specific requirements were asked?
        - criteria: (list) Optional specific criteria to check
        """
        input_data = task_request.input_data
        content = input_data.get("content_to_review")
        original_goal = input_data.get("context", "General quality check")
        specific_criteria = input_data.get("criteria", [])
        
        if not content:
            return {"error": "No content provided for review"}

        # Format content for the LLM
        formatted_content = json.dumps(content, indent=2) if isinstance(content, (dict, list)) else str(content)
        
        # Define the QA task
        qa_task = Task(
            description=f"""
            Conduct a Quality Assurance Audit on the following AI-generated output.
            
            ORIGINAL GOAL/CONTEXT:
            {original_goal}
            
            CONTENT TO REVIEW:
            {formatted_content[:15000]}  # Truncated to avoid context limits if massive
            
            SPECIFIC CRITERIA TO CHECK:
            {', '.join(specific_criteria) if specific_criteria else 'Completeness, Accuracy, Actionability, Formatting'}
            
            YOUR TASK:
            1. Score the content (1-10) on: Relevance, Depth, and Clarity.
            2. Identify any hallucinations, vague statements, or missing sections.
            3. Provide 3 concrete suggestions for improvement.
            4. determine if this output is "Client Ready" (Pass/Fail).
            
            Output MUST be in valid JSON format with keys:
            overall_score, relevance_score, clarity_score, feedback_summary, improvement_suggestions, is_approved
            """,
            agent=self.crewai_agent,
            expected_output="Detailed JSON Quality Audit Report"
        )
        
        # Execute QA
        crew = Crew(
            agents=[self.crewai_agent],
            tasks=[qa_task],
            process=Process.sequential,
            verbose=True
        )
        
        result_raw = crew.kickoff()
        
        # Parse result (attempt to extract JSON if wrapped in text)
        parsed_result = self._parse_result(str(result_raw))
        
        # Log the audit
        self.logger.info(
            "QA Audit Completed", 
            score=parsed_result.get('overall_score'), 
            approved=parsed_result.get('is_approved')
        )
        
        return {
            "qa_report": parsed_result,
            "audited_at": datetime.now(timezone.utc).isoformat(),
            "original_content_id": task_request.metadata.get("source_task_id")
        }

    def _parse_result(self, text: str) -> Dict[str, Any]:
        """Helper to safely parse JSON from LLM output"""
        try:
            # Clean up markdown code blocks if present
            clean_text = text.replace("```json", "").replace("```", "").strip()
            return json.loads(clean_text)
        except json.JSONDecodeError:
            # Fallback if LLM didn't return pure JSON
            self.logger.warning("Failed to parse QA JSON, returning raw text")
            return {
                "overall_score": 0,
                "is_approved": False,
                "feedback_summary": "Output format error - raw text returned",
                "raw_output": text
            }
