# BizOSaaS Infrastructure Project - STAGING Environment
# 3 Core Infrastructure containers for staging deployment

services:
  # ==========================================
  # POSTGRESQL DATABASE
  # Multi-tenant database with pgvector
  # ==========================================
  postgres:
    image: pgvector/pgvector:pg16
    container_name: bizosaas-postgres-staging
    ports:
      - "5433:5432"
    environment:
      - POSTGRES_DB=bizosaas_staging
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=BizOSaaS2025!StagingDB
    volumes:
      - postgres_staging_data:/var/lib/postgresql/data
    networks:
      - dokploy-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 2G
        reservations:
          cpus: '0.1'
          memory: 512M
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d bizosaas_staging"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================
  # REDIS CACHE
  # High-performance caching and sessions
  # ==========================================
  redis:
    image: redis:7-alpine
    container_name: bizosaas-redis-staging
    ports:
      - "6380:6379"
    command: redis-server --appendonly yes --replica-read-only no
    volumes:
      - redis_staging_data:/data
    networks:
      - dokploy-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================
  # HASHICORP VAULT
  # Secrets management
  # ==========================================
  vault:
    image: hashicorp/vault:1.15
    container_name: bizosaas-vault-staging
    ports:
      - "8201:8200"
    environment:
      - VAULT_DEV_ROOT_TOKEN_ID=staging-root-token-bizosaas-2025
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
      - VAULT_ADDR=http://0.0.0.0:8200
    cap_add:
      - IPC_LOCK
    volumes:
      - vault_staging_data:/vault/data
    networks:
      - dokploy-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 256M
        reservations:
          cpus: '0.05'
          memory: 128M
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.vault.rule=Host(`vault.bizoholic.net`)"
      - "traefik.http.routers.vault.entrypoints=websecure"
      - "traefik.http.routers.vault.tls.certresolver=letsencrypt"
      - "traefik.http.services.vault.loadbalancer.server.port=8200"

  # ==========================================
  # TEMPORAL SERVER
  # Workflow orchestration engine
  # ==========================================
  temporal-server:
    image: temporalio/auto-setup:1.22.0
    container_name: bizosaas-temporal-server-staging
    ports:
      - "7234:7233"
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=admin
      - POSTGRES_PWD=BizOSaaS2025!StagingDB
      - POSTGRES_SEEDS=bizosaas-postgres-staging
      - POSTGRES_DB=temporal
      # - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
    networks:
      - dokploy-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 256M
    depends_on:
      - postgres
    healthcheck:
      test: ["CMD", "temporal", "operator", "cluster", "health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ==========================================
  # TEMPORAL UI
  # Workflow management interface
  # ==========================================
  temporal-ui:
    image: temporalio/ui:2.21.0
    container_name: bizosaas-temporal-ui-staging
    ports:
      - "8083:8080"
    environment:
      - TEMPORAL_ADDRESS=bizosaas-temporal-server-staging:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:8083,https://temporal.bizoholic.net
    networks:
      - dokploy-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
    depends_on:
      - temporal-server
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.temporal-ui.rule=Host(`temporal.bizoholic.net`)"
      - "traefik.http.routers.temporal-ui.entrypoints=websecure"
      - "traefik.http.routers.temporal-ui.tls.certresolver=letsencrypt"
      - "traefik.http.services.temporal-ui.loadbalancer.server.port=8080"

  # ==========================================
  # APACHE SUPERSET - DEPRECATED / REMOVED
  # Analytics and Business Intelligence
  # ==========================================
  # Service removed to save resources.
  # Use Grafana with Postgres datasource for BI.
  # MONITORING STACK
  # Prometheus, Grafana, Loki
  # ==========================================
  loki:
    image: grafana/loki:2.9.0
    container_name: bizosaas-loki-staging
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - dokploy-network
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.loki.rule=Host(`loki.bizoholic.net`)"
      - "traefik.http.routers.loki.entrypoints=websecure"
      - "traefik.http.routers.loki.tls.certresolver=letsencrypt"
      - "traefik.http.services.loki.loadbalancer.server.port=3100"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    volumes:
      - loki_staging_data:/loki

  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: bizosaas-prometheus-staging
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_staging_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - dokploy-network
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`prometheus.bizoholic.net`)"
      - "traefik.http.routers.prometheus.entrypoints=websecure"
      - "traefik.http.routers.prometheus.tls.certresolver=letsencrypt"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  grafana:
    image: grafana/grafana:10.2.0
    container_name: bizosaas-grafana-staging
    ports:
      - "8084:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=BizOSaaS2025!Grafana
      - GF_USERS_ALLOW_SIGN_UP=false
      # Grafana SSO Configuration
      - GF_SERVER_ROOT_URL=https://grafana.bizoholic.net
      - GF_AUTH_GENERIC_OAUTH_ENABLED=true
      - GF_AUTH_GENERIC_OAUTH_NAME=BizOSaaS SSO
      - GF_AUTH_GENERIC_OAUTH_ALLOW_SIGN_UP=true
      - GF_AUTH_GENERIC_OAUTH_CLIENT_ID=uNeNjOeHpst6Q83o1lmUNCU2S2iZ9vg2hHajSYGF
      - GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET=gmupMMr6KkxLyb5kgpRqhAq0yVUIUv0Oj1oa8fk95fCUsyVhhF728KPHpDGwwBQAFObfkIUds4zpCQM4I7wsiGT8NSTGpvpJ63vDiUUwKqcni62U7ceG52ayDgU96xbR
      - GF_AUTH_GENERIC_OAUTH_SCOPES=openid profile email
      - GF_AUTH_GENERIC_OAUTH_AUTH_URL=https://sso.bizoholic.net/application/o/authorize/
      - GF_AUTH_GENERIC_OAUTH_TOKEN_URL=https://sso.bizoholic.net/application/o/token/
      - GF_AUTH_GENERIC_OAUTH_API_URL=https://sso.bizoholic.net/application/o/userinfo/
    volumes:
      - grafana_staging_data:/var/lib/grafana
    networks:
      - dokploy-network
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`grafana.bizoholic.net`)"
      - "traefik.http.routers.grafana.entrypoints=websecure"
      - "traefik.http.routers.grafana.tls.certresolver=letsencrypt"
      - "traefik.http.services.grafana.loadbalancer.server.port=3000"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    depends_on:
      - prometheus
      - loki
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3



volumes:
  superset_home:
    driver: local
  postgres_staging_data:
    driver: local
  redis_staging_data:
    driver: local
  vault_staging_data:
    driver: local
  loki_staging_data:
    driver: local
  prometheus_staging_data:
    driver: local
  grafana_staging_data:
    driver: local

networks:
  dokploy-network:
    external: true

# ==================================================
# INFRASTRUCTURE PROJECT SUMMARY:
# ==================================================
# Container Count: 6 (complete infrastructure + analytics)
# Purpose: Complete infrastructure for staging environment
# External Access: PostgreSQL (5433), Redis (6380), Vault (8201), Temporal (7234), Temporal UI (8083), Superset (8088)
# Dependencies: None (foundation layer)
# Services:
#   - PostgreSQL with pgvector
#   - Redis cache
#   - Vault secrets management
#   - Temporal Server (workflow orchestration)
#   - Temporal UI (workflow management interface)
#   - Apache Superset (analytics and BI dashboards)
# ==================================================
